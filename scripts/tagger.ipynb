{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T10:11:07.248761Z",
     "start_time": "2021-01-19T10:10:38.606051Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "# load model\n",
    "model1 = torch.hub.load('/home/qzlzdy/Python/RF5_danbooru-pretrained_master', 'resnet50', source='local')\n",
    "model1.eval()\n",
    "model2 = torch.hub.load('/home/qzlzdy/Python/RF5_danbooru-pretrained_master', 'resnet50', source='local')\n",
    "model2.eval()\n",
    "# preprocess function\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(360),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.7137, 0.6628, 0.6519], std=[0.2970, 0.3017, 0.2979])\n",
    "])\n",
    "# load categories\n",
    "with open('class_names_6000.json', 'r') as f:\n",
    "    class_names = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T10:11:10.037076Z",
     "start_time": "2021-01-19T10:11:09.968204Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import os\n",
    "import threading\n",
    "\n",
    "def clear_temporary_directory():\n",
    "    temp = Path('../datasets/danbooru-images/temp/')\n",
    "    all_temp_files = temp.glob('*')\n",
    "    print('clearing temporary dictory...')\n",
    "    for path in all_temp_files:\n",
    "        os.remove(str(path))\n",
    "\n",
    "class ConvertRGB(threading.Thread):\n",
    "    def __init__(self, index):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.load_path = '../datasets/danbooru-images/danbooru-images/0{:03d}/'.format(index)\n",
    "        self.name = \"Convertor {}\".format(index)\n",
    "\n",
    "    def run(self):\n",
    "        data_root = Path(self.load_path)\n",
    "        all_images = data_root.glob('*')\n",
    "        all_images = [str(path) for path in all_images]\n",
    "        save_path = '../datasets/danbooru-images/temp/{}'\n",
    "        \n",
    "        for path in all_images:\n",
    "            Image.open(path).convert('RGB').save(save_path.format(path[49:]))     \n",
    "\n",
    "def fill_temporary_directory(index):\n",
    "    beg = 4 * index\n",
    "    end = beg + 4\n",
    "    threads = [ConvertRGB(i) for i in range(beg, end)]\n",
    "    print('filling temporary directory...')\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "mutex = threading.Lock() # tag_file\n",
    "class Tagger(threading.Thread):\n",
    "    def __init__(self, name, model, all_images):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.all_images = all_images\n",
    "        self.model = model\n",
    "        self.total = len(all_images)\n",
    "    \n",
    "    def run(self):\n",
    "        for i, path in enumerate(self.all_images):\n",
    "            image = Image.open(path)\n",
    "            image = preprocess(image)\n",
    "            image = image.unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                probs = self.model(image)\n",
    "            probs = torch.sigmoid(probs[0])\n",
    "            tmp = probs[probs > 0.25]\n",
    "            inds = probs.argsort(descending=True)\n",
    "            tags = [class_names[i] for i in inds[0:len(tmp)]]\n",
    "            tags = {'id': path[33:], 'tags': tags}\n",
    "            tags = json.dumps(tags)\n",
    "            mutex.acquire()\n",
    "            tag_file.write(tags + '\\n')\n",
    "            mutex.release()\n",
    "            if i % 100 == 0:\n",
    "                print('{}: tagging............({}/{})'.format(self.name, i, self.total))\n",
    "\n",
    "def tag_temporary_directory():\n",
    "    data_root = Path('../datasets/danbooru-images/temp/')\n",
    "    all_images = data_root.glob('*')\n",
    "    all_images = [str(path) for path in all_images]\n",
    "    half = len(all_images) // 2\n",
    "    threads = [\n",
    "        Tagger('Tagger1', model1, all_images[:half]),\n",
    "        Tagger('Tagger2', model2, all_images[half:])\n",
    "    ]\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "def single_thread_tagger():\n",
    "    data_root = Path('../datasets/danbooru-images/temp/')\n",
    "    all_images = data_root.glob('*')\n",
    "    all_images = [str(path) for path in all_images]\n",
    "    thread = Tagger('Tagger1', model1, all_images)\n",
    "    thread.start()\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-19T10:43:08.409510Z",
     "start_time": "2021-01-19T10:11:20.004801Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting round 37\n",
      "clearing temporary dictory...\n",
      "filling temporary directory...\n",
      "Tagger1: tagging............(0/3319)\n",
      "Tagger2: tagging............(0/3320)\n",
      "Tagger2: tagging............(100/3320)\n",
      "Tagger1: tagging............(100/3319)\n",
      "Tagger2: tagging............(200/3320)\n",
      "Tagger1: tagging............(200/3319)\n",
      "Tagger2: tagging............(300/3320)\n",
      "Tagger1: tagging............(300/3319)\n",
      "Tagger2: tagging............(400/3320)\n",
      "Tagger1: tagging............(400/3319)\n",
      "Tagger2: tagging............(500/3320)\n",
      "Tagger1: tagging............(500/3319)\n",
      "Tagger2: tagging............(600/3320)\n",
      "Tagger1: tagging............(600/3319)\n",
      "Tagger2: tagging............(700/3320)\n",
      "Tagger1: tagging............(700/3319)\n",
      "Tagger2: tagging............(800/3320)\n",
      "Tagger1: tagging............(800/3319)\n",
      "Tagger2: tagging............(900/3320)\n",
      "Tagger1: tagging............(900/3319)\n",
      "Tagger2: tagging............(1000/3320)\n",
      "Tagger1: tagging............(1000/3319)\n",
      "Tagger2: tagging............(1100/3320)\n",
      "Tagger1: tagging............(1100/3319)\n",
      "Tagger2: tagging............(1200/3320)\n",
      "Tagger1: tagging............(1200/3319)\n",
      "Tagger2: tagging............(1300/3320)\n",
      "Tagger1: tagging............(1300/3319)\n",
      "Tagger2: tagging............(1400/3320)\n",
      "Tagger1: tagging............(1400/3319)\n",
      "Tagger2: tagging............(1500/3320)\n",
      "Tagger1: tagging............(1500/3319)\n",
      "Tagger2: tagging............(1600/3320)\n",
      "Tagger1: tagging............(1600/3319)\n",
      "Tagger2: tagging............(1700/3320)\n",
      "Tagger1: tagging............(1700/3319)\n",
      "Tagger2: tagging............(1800/3320)\n",
      "Tagger1: tagging............(1800/3319)\n",
      "Tagger2: tagging............(1900/3320)\n",
      "Tagger1: tagging............(1900/3319)\n",
      "Tagger2: tagging............(2000/3320)\n",
      "Tagger1: tagging............(2000/3319)\n",
      "Tagger2: tagging............(2100/3320)\n",
      "Tagger1: tagging............(2100/3319)\n",
      "Tagger2: tagging............(2200/3320)\n",
      "Tagger1: tagging............(2200/3319)\n",
      "Tagger2: tagging............(2300/3320)\n",
      "Tagger1: tagging............(2300/3319)\n",
      "Tagger2: tagging............(2400/3320)\n",
      "Tagger1: tagging............(2400/3319)\n",
      "Tagger2: tagging............(2500/3320)\n",
      "Tagger1: tagging............(2500/3319)\n",
      "Tagger2: tagging............(2600/3320)\n",
      "Tagger1: tagging............(2600/3319)\n",
      "Tagger2: tagging............(2700/3320)\n",
      "Tagger1: tagging............(2700/3319)\n",
      "Tagger2: tagging............(2800/3320)\n",
      "Tagger1: tagging............(2800/3319)\n",
      "Tagger2: tagging............(2900/3320)\n",
      "Tagger1: tagging............(2900/3319)\n",
      "Tagger2: tagging............(3000/3320)\n",
      "Tagger1: tagging............(3000/3319)\n",
      "Tagger2: tagging............(3100/3320)\n",
      "Tagger1: tagging............(3100/3319)\n",
      "Tagger2: tagging............(3200/3320)\n",
      "Tagger1: tagging............(3200/3319)\n",
      "Tagger2: tagging............(3300/3320)\n",
      "Tagger1: tagging............(3300/3319)\n"
     ]
    }
   ],
   "source": [
    "for i in range(37, 38):\n",
    "    print('starting round', i)\n",
    "    clear_temporary_directory()\n",
    "    fill_temporary_directory(i)\n",
    "    b = 4 * i\n",
    "    e = b + 3\n",
    "    tag_file = open('./danbooru-tags/{}-{}.json'.format(b, e), 'w')\n",
    "    tag_temporary_directory()\n",
    "    tag_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T05:06:06.665200Z",
     "start_time": "2021-01-18T05:06:06.649885Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273027.jpg\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "# debug\n",
    "print(all_images[0][33:])\n",
    "print(len('../datasets/danbooru-images/temp/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alternative loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-18T05:49:23.683249Z",
     "start_time": "2021-01-18T05:06:14.166319Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagger2: tagging............(0/4443)\n",
      "Tagger1: tagging............(0/4442)\n",
      "Tagger1: tagging............(100/4442)\n",
      "Tagger2: tagging............(100/4443)\n",
      "Tagger1: tagging............(200/4442)\n",
      "Tagger2: tagging............(200/4443)\n",
      "Tagger1: tagging............(300/4442)\n",
      "Tagger2: tagging............(300/4443)\n",
      "Tagger1: tagging............(400/4442)\n",
      "Tagger2: tagging............(400/4443)\n",
      "Tagger1: tagging............(500/4442)\n",
      "Tagger2: tagging............(500/4443)\n",
      "Tagger1: tagging............(600/4442)\n",
      "Tagger2: tagging............(600/4443)\n",
      "Tagger1: tagging............(700/4442)\n",
      "Tagger2: tagging............(700/4443)\n",
      "Tagger1: tagging............(800/4442)\n",
      "Tagger2: tagging............(800/4443)\n",
      "Tagger1: tagging............(900/4442)\n",
      "Tagger2: tagging............(900/4443)\n",
      "Tagger1: tagging............(1000/4442)\n",
      "Tagger2: tagging............(1000/4443)\n",
      "Tagger1: tagging............(1100/4442)\n",
      "Tagger2: tagging............(1100/4443)\n",
      "Tagger1: tagging............(1200/4442)\n",
      "Tagger2: tagging............(1200/4443)\n",
      "Tagger1: tagging............(1300/4442)\n",
      "Tagger2: tagging............(1300/4443)\n",
      "Tagger1: tagging............(1400/4442)\n",
      "Tagger2: tagging............(1400/4443)\n",
      "Tagger1: tagging............(1500/4442)\n",
      "Tagger2: tagging............(1500/4443)\n",
      "Tagger1: tagging............(1600/4442)\n",
      "Tagger2: tagging............(1600/4443)\n",
      "Tagger1: tagging............(1700/4442)\n",
      "Tagger2: tagging............(1700/4443)\n",
      "Tagger1: tagging............(1800/4442)\n",
      "Tagger2: tagging............(1800/4443)\n",
      "Tagger1: tagging............(1900/4442)\n",
      "Tagger2: tagging............(1900/4443)\n",
      "Tagger1: tagging............(2000/4442)\n",
      "Tagger2: tagging............(2000/4443)\n",
      "Tagger1: tagging............(2100/4442)\n",
      "Tagger2: tagging............(2100/4443)\n",
      "Tagger1: tagging............(2200/4442)\n",
      "Tagger2: tagging............(2200/4443)\n",
      "Tagger1: tagging............(2300/4442)\n",
      "Tagger2: tagging............(2300/4443)\n",
      "Tagger1: tagging............(2400/4442)\n",
      "Tagger2: tagging............(2400/4443)\n",
      "Tagger1: tagging............(2500/4442)\n",
      "Tagger2: tagging............(2500/4443)\n",
      "Tagger1: tagging............(2600/4442)\n",
      "Tagger2: tagging............(2600/4443)\n",
      "Tagger1: tagging............(2700/4442)\n",
      "Tagger2: tagging............(2700/4443)\n",
      "Tagger1: tagging............(2800/4442)\n",
      "Tagger2: tagging............(2800/4443)\n",
      "Tagger1: tagging............(2900/4442)\n",
      "Tagger2: tagging............(2900/4443)\n",
      "Tagger1: tagging............(3000/4442)\n",
      "Tagger2: tagging............(3000/4443)\n",
      "Tagger1: tagging............(3100/4442)\n",
      "Tagger2: tagging............(3100/4443)\n",
      "Tagger1: tagging............(3200/4442)\n",
      "Tagger2: tagging............(3200/4443)\n",
      "Tagger1: tagging............(3300/4442)\n",
      "Tagger2: tagging............(3300/4443)\n",
      "Tagger1: tagging............(3400/4442)\n",
      "Tagger2: tagging............(3400/4443)\n",
      "Tagger1: tagging............(3500/4442)\n",
      "Tagger2: tagging............(3500/4443)\n",
      "Tagger1: tagging............(3600/4442)\n",
      "Tagger2: tagging............(3600/4443)\n",
      "Tagger1: tagging............(3700/4442)\n",
      "Tagger2: tagging............(3700/4443)\n",
      "Tagger1: tagging............(3800/4442)\n",
      "Tagger2: tagging............(3800/4443)\n",
      "Tagger1: tagging............(3900/4442)\n",
      "Tagger2: tagging............(3900/4443)\n",
      "Tagger1: tagging............(4000/4442)\n",
      "Tagger2: tagging............(4000/4443)\n",
      "Tagger1: tagging............(4100/4442)\n",
      "Tagger2: tagging............(4100/4443)\n",
      "Tagger1: tagging............(4200/4442)\n",
      "Tagger2: tagging............(4200/4443)\n",
      "Tagger1: tagging............(4300/4442)\n",
      "Tagger2: tagging............(4300/4443)\n",
      "Tagger1: tagging............(4400/4442)\n",
      "Tagger2: tagging............(4400/4443)\n"
     ]
    }
   ],
   "source": [
    "i = 6\n",
    "clear_temporary_direcory()\n",
    "fill_temporary_directory(i)\n",
    "b = 4 * i\n",
    "e = b + 3\n",
    "tag_file = open('./danbooru-tags/{}-{}.json'.format(b, e), 'w')\n",
    "single_thread_tagger(ind)\n",
    "tag_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "388.4px",
    "left": "854px",
    "right": "20px",
    "top": "116px",
    "width": "545px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
